{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOUEA3lceT4Yg3pUse8aoJa",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/madarshb19/PyTorch_Lightning/blob/main/PyTorchLightningBaseCode.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YLdYMcwo1Eem"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.transforms as transforms\n",
        "from torch import nn, optim\n",
        "from torch.utils.data import DataLoader\n",
        "from tqdm import tqdm\n",
        "from torch.utils.data import random_split\n",
        "\n",
        "\n",
        "class NN(nn.Module):\n",
        "    def __init__(self, input_size, num_classes):\n",
        "        super().__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 50)\n",
        "        self.fc2 = nn.Linear(50, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "# Set device cuda for GPU if it's available otherwise run on the CPU\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Hyperparameters\n",
        "input_size = 784\n",
        "num_classes = 10\n",
        "learning_rate = 0.001\n",
        "batch_size = 64\n",
        "num_epochs = 3\n",
        "\n",
        "# Load Data\n",
        "entire_dataset = datasets.MNIST(\n",
        "    root=\"dataset/\", train=True, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "train_ds, val_ds = random_split(entire_dataset, [50000, 10000])\n",
        "test_ds = datasets.MNIST(\n",
        "    root=\"dataset/\", train=False, transform=transforms.ToTensor(), download=True\n",
        ")\n",
        "train_loader = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
        "val_loader = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n",
        "test_loader = DataLoader(dataset=test_ds, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "# Initialize network\n",
        "model = NN(input_size=input_size, num_classes=num_classes).to(device)\n",
        "\n",
        "# Loss and optimizer\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "# Train Network\n",
        "for epoch in range(num_epochs):\n",
        "    for batch_idx, (data, targets) in enumerate(tqdm(train_loader)):\n",
        "        # Get data to cuda if possible\n",
        "        data = data.to(device=device)\n",
        "        targets = targets.to(device=device)\n",
        "\n",
        "        # Get to correct shape\n",
        "        data = data.reshape(data.shape[0], -1)\n",
        "\n",
        "        # Forward\n",
        "        scores = model(data)\n",
        "        loss = criterion(scores, targets)\n",
        "\n",
        "        # Backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "\n",
        "        # Gradient descent or adam step\n",
        "        optimizer.step()\n",
        "\n",
        "\n",
        "# Check accuracy on training & test to see how good our model\n",
        "def check_accuracy(loader, model):\n",
        "    num_correct = 0\n",
        "    num_samples = 0\n",
        "    model.eval()\n",
        "\n",
        "    # We don't need to keep track of gradients here so we wrap it in torch.no_grad()\n",
        "    with torch.no_grad():\n",
        "        # Loop through the data\n",
        "        for x, y in loader:\n",
        "\n",
        "            # Move data to device\n",
        "            x = x.to(device=device)\n",
        "            y = y.to(device=device)\n",
        "\n",
        "            # Get to correct shape\n",
        "            x = x.reshape(x.shape[0], -1)\n",
        "\n",
        "            # Forward pass\n",
        "            scores = model(x)\n",
        "            _, predictions = scores.max(1)\n",
        "\n",
        "            # Check how many we got correct\n",
        "            num_correct += (predictions == y).sum()\n",
        "\n",
        "            # Keep track of number of samples\n",
        "            num_samples += predictions.size(0)\n",
        "\n",
        "    model.train()\n",
        "    return num_correct / num_samples\n",
        "\n",
        "\n",
        "# Check accuracy on training & test to see how good our model\n",
        "model.to(device)\n",
        "print(f\"Accuracy on training set: {check_accuracy(train_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on validation set: {check_accuracy(val_loader, model)*100:.2f}\")\n",
        "print(f\"Accuracy on test set: {check_accuracy(test_loader, model)*100:.2f}\")"
      ]
    }
  ]
}